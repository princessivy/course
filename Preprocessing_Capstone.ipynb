{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing Capstone.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/pds2122/capstone-project-kabobe/blob/main/Preprocessing_Capstone.ipynb",
      "authorship_tag": "ABX9TyO2bcIMYLJt67yWb9suXrf/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princessivy/course/blob/main/Preprocessing_Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs & Imports"
      ],
      "metadata": {
        "id": "FDGdPU29MSVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WNbii3pkMOqZ",
        "outputId": "e1a910e6-9e09-4a12-a5f7-47dfb1f6e356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5 MB 14.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 981 kB 14.9 MB/s \n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install ndjson --quiet\n",
        "!pip install beautifulsoup4 --quiet\n",
        "!pip install html2text --quiet\n",
        "!pip install nltk --quiet\n",
        "!pip install HanTa --quiet\n",
        "!pip install langdetect --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ndjson\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import gzip\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from collections import Counter, OrderedDict\n",
        "from google.colab import drive\n",
        "import html2text\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction import text\n",
        "from HanTa import HanoverTagger as ht\n",
        "from langdetect import detect\n",
        "import gc\n",
        "gc.enable()"
      ],
      "metadata": {
        "id": "AtG0Q4BBNlEk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test-Dataset"
      ],
      "metadata": {
        "id": "8VyQ5CGxN1kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/gdrive')\n",
        "data_path = Path('/gdrive/MyDrive/industry_data/')\n",
        "file_name = 'test_small.ndjson.gz'\n",
        "\n",
        "with gzip.open(data_path/file_name, \"rt\", encoding='UTF-8') as file:\n",
        "    data = ndjson.load(file)\n",
        "df_test = pd.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BBg5hWkNrOp",
        "outputId": "5d37afa5-160b-4d02-9833-96acc7b13f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for null entries\n",
        "if df_test.isnull().any(axis=None):\n",
        "    print(\"\\nPreview of data with null values:\\nxxxxxxxxxxxxx\")\n",
        "    print(df_est[df_test.isnull().any(axis=1)].head(3))\n",
        "    missingno.matrix(df_test)\n",
        "    plt.show()\n",
        "else:\n",
        "  print('No null entries found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFf32zloN9eF",
        "outputId": "72503ad3-bdb5-489d-8802-bd8a78ab122f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No null entries found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate count statistics of duplicate entries\n",
        "if len(df_test[df_test.duplicated()]) > 0:\n",
        "    print(\"No. of duplicated entries: \", len(df_test[df_test.duplicated()]))\n",
        "    print(df_test[df_test.duplicated(keep=False)].sort_values(by=list(df_test.columns)).head())\n",
        "else:\n",
        "    print(\"No duplicated entries found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AgvR25NOLtb",
        "outputId": "0654cf6d-51d8-43a6-da81-4fb92be7aba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No duplicated entries found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train-Dataset"
      ],
      "metadata": {
        "id": "w7WamG8dOmz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/gdrive')\n",
        "data_path = Path('/gdrive/MyDrive/industry_data/')\n",
        "file_name = 'train_small.ndjson.gz'\n",
        "with gzip.open(data_path/file_name, \"rt\", encoding='UTF-8') as file:\n",
        "    data = []\n",
        "    data = [ndjson.loads(line) for line in file]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSl9XlPHOeUY",
        "outputId": "38805973-e988-4a74-b4a3-1ac1bdfbb0d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nested List rausholen, Flat-List erzeugen, um Daten in DataFrame zu bekommen\n",
        "flat_list = [item for sublist in data for item in sublist]\n",
        "df_train = pd.DataFrame(flat_list)"
      ],
      "metadata": {
        "id": "CBuF1gZ2Otv1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for null entries\n",
        "if df_train.isnull().any(axis=None):\n",
        "    print(\"\\nPreview of data with null values:\\nxxxxxxxxxxxxx\")\n",
        "    print(df_train[df_train.isnull().any(axis=1)].head(3))\n",
        "    missingno.matrix(df_train)\n",
        "    plt.show()\n",
        "else:\n",
        "  print('No null entries found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy2lSaIQOvUE",
        "outputId": "2f2a2a3b-33ca-41ff-d80b-8a7dee1d7d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No null entries found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate count statistics of duplicate entries\n",
        "if len(df_train[df_train.duplicated()]) > 0:\n",
        "    print(\"No. of duplicated entries: \", len(df_train[df_train.duplicated()]))\n",
        "    print(df_train[df_train.duplicated(keep=False)].sort_values(by=list(df_train.columns)).head())\n",
        "else:\n",
        "    print(\"No duplicated entries found\")"
      ],
      "metadata": {
        "id": "jCLSMCcsOyKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRtXry2sRFh7",
        "outputId": "453fb6a1-a4d6-4bb4-cf61-39e123e5011a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "310"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HTML Feature-Checkout"
      ],
      "metadata": {
        "id": "6fJp9_q7O1jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking out Tag-Occurence"
      ],
      "metadata": {
        "id": "hkeKfI3eSU9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tags = [] #der ersten 1000 Datensätze\n",
        "\n",
        "for i in range(1000): #len(df_train)\n",
        "  soup = BeautifulSoup(data[i][0]['html'], 'html.parser')\n",
        "  #for tag in soup.findAll(True):\n",
        "    #print(tag.name)\n",
        "  tags = set(tag.name for tag in BeautifulSoup(data[i][0]['html'], 'html.parser').find_all()) # oder direkt hier set (um zu schauen, ob es überhaupt in allen Datensätzen vorkommt; wenn später <1000 dann nämlich nicht)\n",
        "  all_tags.extend(tags)\n",
        "\n",
        "  #print(data[i][0]['url'])\n",
        "  #print(soup.get_text()[:1024])\n",
        "  #print(tags)"
      ],
      "metadata": {
        "id": "LuujsgFLSX3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oder all_tags_set\n",
        "counted = Counter(all_tags)\n",
        "OrderedDict(counted.most_common())"
      ],
      "metadata": {
        "id": "pkGrDfM8SZVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Whole Text between Tags"
      ],
      "metadata": {
        "id": "ZJaJxFc-PXoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.mode.chained_assignment = None"
      ],
      "metadata": {
        "id": "aolOjlJ9lO5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_to_text(html):\n",
        "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "    # kill all script and style elements\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.extract()    # rip it out\n",
        "\n",
        "    # get text\n",
        "    text = soup.get_text()\n",
        "\n",
        "    # break into lines and remove leading and trailing space on each\n",
        "    lines = (line.strip() for line in text.splitlines())\n",
        "    # break multi-headlines into a line each\n",
        "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    # drop blank lines\n",
        "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "HfZlZg1odxu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eliminate htlm elements from text\n",
        "\n",
        "df_train = df_train.assign(html_to_text='')\n",
        "for line in range(0, len(df_train)):\n",
        "  #print(df_train.iloc[line]) #debugging\n",
        "  #content = parse_html(df_train.html[line])\n",
        "  content = parse_to_text(df_train.html[line])\n",
        "  df_train.html_to_text[line] = content"
      ],
      "metadata": {
        "id": "mBC8A3XhT7VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_work = df_train.head(100).copy() #----------------------------------------"
      ],
      "metadata": {
        "id": "xFsYozlQepZ1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_work"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7wsfPRppmMjy",
        "outputId": "3e67fdd5-3bbb-4243-e17b-75fdc6cda286"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-94d41229-1270-4034-a6cd-24cf188dc353\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>html</th>\n",
              "      <th>industry</th>\n",
              "      <th>industry_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.kaiser-personal-service.de</td>\n",
              "      <td>&lt;!doctype html&gt;\\n&lt;html lang=\"de\"&gt;\\n\\t&lt;head&gt;\\n\\...</td>\n",
              "      <td>137</td>\n",
              "      <td>Human Resources</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://www.brandseven.com</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html class=\"html\" lang=\"de-D...</td>\n",
              "      <td>96</td>\n",
              "      <td>Information Technology and Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://www.beumergroup.com</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html class=\"home page-templa...</td>\n",
              "      <td>135</td>\n",
              "      <td>Mechanical or Industrial Engineering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://www.aurigavision.com</td>\n",
              "      <td>&lt;!doctype html&gt;\\n&lt;!--[if IE 8]&gt;         &lt;html ...</td>\n",
              "      <td>13</td>\n",
              "      <td>Medical Practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.comme-a-la-maison.ch</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"fr\"&gt;\\n&lt;head&gt;\\n\\n&lt;...</td>\n",
              "      <td>48</td>\n",
              "      <td>Construction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>http://www.i-soft-systemhaus.de</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"de\"&gt;\\n\\n&lt;head&gt;\\...</td>\n",
              "      <td>96</td>\n",
              "      <td>Information Technology and Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>http://www.communicode.de</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;&lt;html lang=\"de\"&gt;&lt;head&gt;&lt;script&gt;(...</td>\n",
              "      <td>96</td>\n",
              "      <td>Information Technology and Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>http://www.kuper.de</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;&lt;html lang=\"de\"&gt;&lt;head&gt;&lt;script i...</td>\n",
              "      <td>135</td>\n",
              "      <td>Mechanical or Industrial Engineering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>http://craftworks.at</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n  \\...</td>\n",
              "      <td>96</td>\n",
              "      <td>Information Technology and Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>http://www.gastprodo.com</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de\"&gt;\\n&lt;head&gt;\\n&lt;me...</td>\n",
              "      <td>133</td>\n",
              "      <td>Wholesale</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94d41229-1270-4034-a6cd-24cf188dc353')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94d41229-1270-4034-a6cd-24cf188dc353 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94d41229-1270-4034-a6cd-24cf188dc353');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      url  ...                        industry_label\n",
              "0   http://www.kaiser-personal-service.de  ...                       Human Resources\n",
              "1               http://www.brandseven.com  ...   Information Technology and Services\n",
              "2              http://www.beumergroup.com  ...  Mechanical or Industrial Engineering\n",
              "3             http://www.aurigavision.com  ...                      Medical Practice\n",
              "4         http://www.comme-a-la-maison.ch  ...                          Construction\n",
              "..                                    ...  ...                                   ...\n",
              "95        http://www.i-soft-systemhaus.de  ...   Information Technology and Services\n",
              "96              http://www.communicode.de  ...   Information Technology and Services\n",
              "97                    http://www.kuper.de  ...  Mechanical or Industrial Engineering\n",
              "98                   http://craftworks.at  ...   Information Technology and Services\n",
              "99               http://www.gastprodo.com  ...                             Wholesale\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing"
      ],
      "metadata": {
        "id": "RLVaVqe4nVyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOwrX0A3nbn1",
        "outputId": "8785ec71-94c7-42f1-88a9-fef4184dea31"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/analytics-vidhya/applying-text-classification-using-logistic-regression-a-comparison-between-bow-and-tf-idf-1f1ed1b83640\n",
        "\n",
        "# hier könnten wir sprachenabhängig arbeiten: clean_text_german(), clean_text_english() und anhand des lang-tags anwenden\n",
        "# \n",
        "def clean_text(mixed_text):\n",
        "    '''Text Preprocessing '''\n",
        "    \n",
        "    # convert words to lower case\n",
        "    content = mixed_text.lower()\n",
        "    \n",
        "    # ENGLISH use this for english text\n",
        "    # Expand contractions (you've -> you have)\n",
        "    #if True:\n",
        "    #    text = text.split()\n",
        "    #    new_text = []\n",
        "    #    for word in text:\n",
        "    #        if word in contractions:\n",
        "    #            new_text.append(contractions[word])\n",
        "    #        else:\n",
        "    #            new_text.append(word)\n",
        "    #    text = \" \".join(new_text)\n",
        "    \n",
        "    # Format words and remove unwanted characters\n",
        "    #content = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', content, flags=re.MULTILINE) # brauchen wir nicht mehr, da schon geparst\n",
        "    #content = re.sub(r'\\<a href', ' ', content)\n",
        "    content = re.sub(r'&amp;', '', content) \n",
        "    content = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', content)\n",
        "    content = re.sub(r'<br />', ' ', content)\n",
        "    content = re.sub(r'\\'', ' ', content)\n",
        "    \n",
        "    # remove stopwords\n",
        "    content = content.split()\n",
        "    stops = set(stopwords.words('german'))\n",
        "    content = [w for w in content if not w in stops]\n",
        "    content = ' '.join(content)\n",
        "\n",
        "    # tokenize each word\n",
        "    content =  nltk.WordPunctTokenizer().tokenize(content)\n",
        "    \n",
        "    # lemmatize each token in German (reduce words to stem)\n",
        "    tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
        "    word_list = []\n",
        "    for w in content:\n",
        "        lemma = [lemma for (word,lemma,pos) in tagger.tag_sent(w.split())]\n",
        "        word_list.append(' '.join(lemma))\n",
        "\n",
        "    # ENGLISH use this for english text\n",
        "    # lemmatize each token\n",
        "    #lemm = nltk.stem.WordNetLemmatizer()\n",
        "    #content = list(map(lambda word:list(map(lemm.lemmatize, word)), content))\n",
        "    \n",
        "    return word_list"
      ],
      "metadata": {
        "id": "r-7_XINontaF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train = df_train.assign(html_cleaned='')\n",
        "df_train_work = df_train_work.assign(html_cleaned='')"
      ],
      "metadata": {
        "id": "HvpOp02Nn4Hu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in range(0, len(df_train_work)):\n",
        "    # print(line) #debugging\n",
        "    content = clean_text(df_train_work['html_to_text'][line])\n",
        "    df_train_work.html_cleaned[line] = content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "nkROPhTlokvp",
        "outputId": "ce97b6b3-6924-464c-9949-bf167c570401"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'html_to_text'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ff18bd5597c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_work\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# print(line) #debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_work\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'html_to_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf_train_work\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'html_to_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Specific Tags for additional Features"
      ],
      "metadata": {
        "id": "0Z-1M2WBPgVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getHTML(url):\n",
        "    # später anpassen, wenn wir live-url abfragen! evtl. Fallunterscheidung?!\n",
        "    '''    r = requests.get(url)\n",
        "    r.text'''\n",
        "    return  BeautifulSoup(url, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "## Img-Description from IMG-Tag\n",
        "def getImgDescriptionHTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    results = soup.find_all('img', alt = True)\n",
        "    img_description = []\n",
        "    for x in range(0,len(results)):\n",
        "      first_result = results[x]\n",
        "      img_description.append(first_result['alt'])\n",
        "    \n",
        "    return list(filter(None, img_description))\n",
        "\n",
        "\n",
        "## Title\n",
        "def getTitleHTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    if (soup.title is not None):\n",
        "        return str(soup.title.string)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "## h1\n",
        "def getH1HTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    heading = soup.findAll('h1')\n",
        "    n = len(heading)\n",
        "\n",
        "    liste = []\n",
        "    for x in range(n):\n",
        "      liste.append(str.strip(heading[x].text))\n",
        "\n",
        "    return list(filter(None, liste))\n",
        "\n",
        "\n",
        "## h2\n",
        "def getH2HTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    heading = soup.findAll('h2')\n",
        "    n = len(heading)\n",
        "\n",
        "    liste = []\n",
        "    for x in range(n):\n",
        "      liste.append(str.strip(heading[x].text))\n",
        "\n",
        "    return list(filter(None, liste))\n",
        "\n",
        "\n",
        "## h3\n",
        "def getH3HTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    heading = soup.findAll('h3')\n",
        "    n = len(heading)\n",
        "\n",
        "    liste = []\n",
        "    for x in range(n):\n",
        "      liste.append(str.strip(heading[x].text))\n",
        "\n",
        "    return list(filter(None, liste))\n",
        "\n",
        "\n",
        "## strong - fragwürdig\n",
        "def getStrongHTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    heading = soup.findAll('strong')\n",
        "    n = len(heading)\n",
        "\n",
        "    liste = []\n",
        "    for x in range(n):\n",
        "      liste.append(str.strip(heading[x].text))\n",
        "\n",
        "    return list(filter(None, liste))\n",
        "\n",
        "\n",
        "## bold\n",
        "def getBoldHTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    heading = soup.findAll('bold')\n",
        "    n = len(heading)\n",
        "\n",
        "    liste = []\n",
        "    for x in range(n):\n",
        "      liste.append(str.strip(heading[x].text))\n",
        "\n",
        "    return list(filter(None, liste))\n",
        "  \n",
        "\n",
        "## language code\n",
        "def getLangHTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    body_text = soup.body.get_text()\n",
        "    return detect(body_text)\n",
        "    \n",
        "    \n",
        "## figcaption\n",
        "def getFigCaptionHTMLtag(url):\n",
        "    soup = getHTML(url)\n",
        "\n",
        "    heading = soup.findAll('figcaption')\n",
        "    n = len(heading)\n",
        "\n",
        "    liste = []\n",
        "    for x in range(n):\n",
        "      liste.append(str.strip(heading[x].text))\n",
        "\n",
        "    return list(filter(None, liste))"
      ],
      "metadata": {
        "id": "hW7i0lYFPPtA"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_work = df_train_work.assign(img_alt='', title='', h1='', h2='', h3='', strong='', bold='', lang_code='', figcaption='')"
      ],
      "metadata": {
        "id": "9-j0cPot2Cdy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Befüllen der Extra-Features\n",
        "\n",
        "for i in range (4, 13):\n",
        "  for j in range(0, len(df_train_work)):\n",
        "        if i == 4:\n",
        "          df_train_work.iloc[:, i][j] = getImgDescriptionHTMLtag(df_train_work.html[j])\n",
        "        elif i == 5:\n",
        "          df_train_work.iloc[:, i][j] = getTitleHTMLtag(df_train_work.html[j])\n",
        "        elif i == 6:\n",
        "          df_train_work.iloc[:, i][j] = getH1HTMLtag(df_train_work.html[j])\n",
        "        elif i == 7:\n",
        "          df_train_work.iloc[:, i][j] = getH2HTMLtag(df_train_work.html[j])\n",
        "        elif i == 8:\n",
        "          df_train_work.iloc[:, i][j] = getH3HTMLtag(df_train_work.html[j])\n",
        "        elif i == 9:\n",
        "          df_train_work.iloc[:, i][j] = getStrongHTMLtag(df_train_work.html[j])\n",
        "        elif i == 10:\n",
        "          df_train_work.iloc[:, i][j] = getBoldHTMLtag(df_train_work.html[j])\n",
        "        elif i == 11:\n",
        "          df_train_work.iloc[:, i][j] = getLangHTMLtag(df_train_work.html[j])\n",
        "        elif i == 12:\n",
        "          df_train_work.iloc[:, i][j] = getFigCaptionHTMLtag(df_train_work.html[j])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Av3H3Gp52ug",
        "outputId": "75feab95-8305-4959-8acd-ef3aef9fc9b1"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aus List-Elementen in DataFrame einfache Strings machen, um besser cleanen zu können\n",
        "\n",
        "# img\n",
        "for x in range(len(df_train_work)):\n",
        "    df_train_work.img_alt[x] = ' '.join(df_train_work.img_alt[x])\n",
        "\n",
        "# h1\n",
        "for x in range(len(df_train_work)):\n",
        "    df_train_work.h1[x] = ' '.join(df_train_work.h1[x])\n",
        "\n",
        "# h2\n",
        "for x in range(len(df_train_work)):\n",
        "    df_train_work.h2[x] = ' '.join(df_train_work.h2[x])\n",
        "\n",
        "# h3\n",
        "for x in range(len(df_train_work)):\n",
        "    df_train_work.h3[x] = ' '.join(df_train_work.h3[x])\n",
        "\n",
        "# strong\n",
        "for x in range(len(df_train_work)):\n",
        "    df_train_work.strong[x] = ' '.join(df_train_work.strong[x])\n",
        "\n",
        "# bold\n",
        "for x in range(len(df_train_work)):\n",
        "    df_train_work.bold[x] = ' '.join(df_train_work.bold[x])\n",
        "\n",
        "# figcaption\n",
        "for x in range(len(df_train_work)):\n",
        "    df_train_work.figcaption[x] = ' '.join(df_train_work.figcaption[x])"
      ],
      "metadata": {
        "id": "15PG8NnnO2oT",
        "outputId": "02e08c38-dc3a-4355-9b71-27936e35af90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alle extra-features durchgehen\n",
        "columns = df_train_work.columns.tolist()\n",
        "columns = columns[4:13]"
      ],
      "metadata": {
        "id": "lr6pYEXPRwDF"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alle extra-features durch clean_text schicken\n",
        "for x in columns:\n",
        "    for y in range(len(df_train_work)):\n",
        "        df_train_work[x][y] = clean_text(df_train_work[x][y])"
      ],
      "metadata": {
        "id": "yUnqbMXzSM4D",
        "outputId": "07f7ac99-8da3-4e00-f4b3-f1ca7ef192fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datei(en) exportieren"
      ],
      "metadata": {
        "id": "zyk0NWAyY0wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_work.to_json('train_preprocessed.json')"
      ],
      "metadata": {
        "id": "tJoZxxx_Y9QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## wieder einlesen:\n",
        "\n",
        "#df = pd.read_json('File Name.json')"
      ],
      "metadata": {
        "id": "_BVUgR1eWsFw"
      },
      "execution_count": 126,
      "outputs": []
    }
  ]
}